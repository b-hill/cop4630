{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOWDkDs12xkCdGHfgeh4Ja8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/b-hill/cop4630/blob/master/hw5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBLJkFgm2CjY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "127f318f-3e6b-4073-f503-a0648ea86752"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm\n",
        "from sklearn import datasets\n",
        "from sklearn import cluster\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Conv2D, Flatten, MaxPool2D\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "from keras.applications import MobileNet\n",
        "\n",
        "iris = datasets.load_iris()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gth_4vByaUkw",
        "colab_type": "text"
      },
      "source": [
        "# General Concepts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dZ2bZ5vckVB",
        "colab_type": "text"
      },
      "source": [
        "Artifical Intelligence, Machine Learning and Deep Learning are all deeply intertwined. An accurate description of their relationships to eachother would be a Russian nesting doll. AI is the largest. ML is in the middle, a subset of AI. DL is the smallest, a subset of both AI and ML (1). \n",
        "\n",
        "![Diagram](https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcSPl_Vby9f4oJrOKANAd8gukPY29jNoredJEbvJIr6tV5JYw5ZK&usqp=CAU)(7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buXmBbzWaosB",
        "colab_type": "text"
      },
      "source": [
        "## What is AI?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoZqbj6La2wR",
        "colab_type": "text"
      },
      "source": [
        "In the words of Professor Wocjan, **Artificial Intelligence** is just an umbrella term for a program that does something smart (1). Usually, this \"something smart\" is making a decison based on the what the user wants. This decision could be anything from \"How much should i tip my server?\" to \"What kind of flower is this?\" to even \"Does this picture contain a cat or a dog?\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCw-D6SWcHzf",
        "colab_type": "text"
      },
      "source": [
        "### Symbolic AI vs Non-Symbolic AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPbbwlgscJaT",
        "colab_type": "text"
      },
      "source": [
        "If we were to draw a Venn Diagram of AI and Machine Learning, you would get 2 concentric Cirlces where the AI circle completely encompasses the ML circle. The area outside the ML circle but inside the AI circle would be **Symbolic AI**. The critical difference isnt what you expect the AI to do but it is instead *how* you expect the AI to accomplish it. With Symbolic AI, the program itself is a set of rules created by the developer. The user than introduces an input and the program produces an output. **Non-Symbolic AI** is the same idea with the order of operations slightly flipped. Here, the program is a *derived set of rules*. The machine learns and creates rules based on what the user expects given an input and expected output. \n",
        "\n",
        "Symbolic AI can be thought of as similar to a flowchart. The rules are layed out already like a pipeline. \n",
        "\n",
        "![Symbolic AI](https://www.breezetree.com/images/simple-flow-chart-example.png)(8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj1LXKPxasCV",
        "colab_type": "text"
      },
      "source": [
        "## What is Machine Learning?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdYJ04aWfa3B",
        "colab_type": "text"
      },
      "source": [
        "**Machine Learing** otherwise known as Non-Symbolic AI, can be broken down into several categories based on what the developer wants the machine to learn. These categories of learning are: Supervised, Unsupervised, and Reinforcement (2)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db7J621zfz-q",
        "colab_type": "text"
      },
      "source": [
        "### Supervised Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6g4pTJhf4s9",
        "colab_type": "text"
      },
      "source": [
        "In this case **Supervised** refers to the labeling of the expected outputs of the data. A marquee example of Supervised Learning is the Iris Classificiation Problem (3). Essentially the input data is a collection of basic measurements of Iris Flowers. Each of one these flowers is attatched to an Iris flower species *label*. For reference, the 4 measurements are the length and width of both the sepal and petal. So the machine learning program has to determine the rules to predict the Iris flower species based on these parameters. This is a **classification** problem, meaning the output is discrete categorization of the input. The other type is **regression** where the output is continious. An example of regression supervised learning would be predicting a students final class grade based on certain inputs like their sleep schedule and study habits. In this case, the output would be a number not a class. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXBWay25TaBa",
        "colab_type": "code",
        "outputId": "29cf2fd7-b19e-47ca-e298-c48fe6b88bd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Simple example on the iris data set using a Support Vector Machine model\n",
        "classifier = svm.SVC()\n",
        "classifier.fit(iris.data[:-1], iris.target[:-1]) # fit on all but last row\n",
        "prediction = classifier.predict(iris.data[-1:])\n",
        "expected = iris.target[-1:]\n",
        "print(prediction, expected)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2] [2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYaGYFfPj5o6",
        "colab_type": "text"
      },
      "source": [
        "### Unsupervised Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGKIVRkekHZb",
        "colab_type": "text"
      },
      "source": [
        "Unsupervised learning is very similar to supervised learning with one critical difference: there isnt an expeceted output. Instead, the goal of the machine is to make the categories and draw the lines between each class. Keep in mind the job of unsupervised learning is *not* to make the labels but to simply determine the boundries of these hypothetical classes. We can once again use the Iris flower data set. If we were to remove the labels, the machine would instead have to categorize the data set into groups it *thinks* are different species. Essentially, you would pass your data through an unsupervised learning machine if you wnate dto uncver hidden patterns and structures in your data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gmjZzbxVbDO",
        "colab_type": "code",
        "outputId": "86f9d736-13c0-405e-d922-2227db53d21c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Simple example on the iris data set using a K Means clustering model\n",
        "k_means = cluster.KMeans(n_clusters=3) \n",
        "k_means.fit(iris.data)\n",
        "prediction = k_means.labels_[::10]\n",
        "expected = iris.target[::10]\n",
        "print(prediction, expected) # as you can see, the labels are irrelvant. Its \n",
        "                            # just important that the model determined the class\n",
        "                            # boundries"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 1 1 1 1 1 2 2 2 2 2] [0 0 0 0 0 1 1 1 1 1 2 2 2 2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IE0vdqjIljcJ",
        "colab_type": "text"
      },
      "source": [
        "### Reinforcement Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8GokoZXlmXY",
        "colab_type": "text"
      },
      "source": [
        "This branch has a slightly different strucure. The goal is to **Reinforce** the behavior of the model (also known as the agent in RL) to act a certain way or acheive a certain goal. One example is a chess-playing AI. The goal of the AI would be to never lose. The agent would play over and over again, learning the best ways to not lose. It can be thought of as using reinforcement with treats to train a dog. The reward for the dog is a treat and they get it by learning the behavior. For the RL agent the behavior is not losing. Essentially, an agent continously takes in the game state and uses the reward or lack there of to make an action.\n",
        "\n",
        "![Example](https://www.researchgate.net/profile/Roohollah_Amiri/publication/323867253/figure/fig2/AS:606095550738432@1521515848671/Reinforcement-Learning-Agent-and-Environment.png)(9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRzv5yBDaxcC",
        "colab_type": "text"
      },
      "source": [
        "## What is Deep Learning?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ApzYqwIqkAH",
        "colab_type": "text"
      },
      "source": [
        "Deep learning is the process of using layered neural networks to extract features from raw input. Each layer is a different level of abstraction away from the input towards the output. The first layer might define edges and curves, the second might recognize basic shapes until the last layer identifies the content of the picture is revealed, maybe a dog or a cat. \n",
        "\n",
        "![Model](https://www.researchgate.net/profile/Wanli_Xing2/publication/323784695/figure/fig5/AS:613990283628562@1523398099969/Deep-learning-diagram.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oMNWAuhaYiE",
        "colab_type": "text"
      },
      "source": [
        "# Basic Concepts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8KD0m0na00g",
        "colab_type": "text"
      },
      "source": [
        "## What is Linear Regression?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6LCIIK5uuWy",
        "colab_type": "text"
      },
      "source": [
        "**Linear Regression** is a supervised learning method that uses a bias and weights to predict an output given multiple features. Linear Regression is a concept many people are familiar with, commonly knowing it as:\n",
        "\n",
        "y = mx + b\n",
        "\n",
        "However, for ML purposes, it is better written as:\n",
        "\n",
        "$\\hat{y}$ = b + wx\n",
        "\n",
        "Where:\n",
        "- $\\hat{y}$ is the predicted label\n",
        "- b is the bias \n",
        "- w is the wieght of the feature\n",
        "- x is the value of the feature\n",
        "\n",
        "This can also be written as:\n",
        "\n",
        "$\\hat{y}$ = b + $\\sum_{j=1}^{n} w_jx_j$\n",
        "\n",
        "When there is more than one feature realtionship under analysis.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9-PXFABa5r3",
        "colab_type": "text"
      },
      "source": [
        "## What is Logistic Regression?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcGAX1_qyLl_",
        "colab_type": "text"
      },
      "source": [
        "**Logistic Regresion** is very similar to Linear Regression with one simple but major stipulation. Logistic Regression passes the expected output through an activation function, typically the sigmoid function, in order to map the unbounded output to a vlaue between 0 or 1. This makes it very useful for classification problems where as Linear Regression is better for normal regression. \n",
        "\n",
        "If we assume that the activation functuon used is the sigmoid function, the Logistic Regression model looks like this:\n",
        "\n",
        "$\\hat{y'} = sigmoid(\\hat{y}) = sigmoid(b + \\sum_{j=1}^{n} w_jx_j)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpWv_Mt50QfB",
        "colab_type": "text"
      },
      "source": [
        "### Sigmoid Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og5RLXML0TJF",
        "colab_type": "text"
      },
      "source": [
        "Commonly known as the 'S Curve', the **Sigmoid Function** is one of many activation functions used to classify a models output. It does this by modifiying the output and sometimes also imposing a threshold on the result. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o9M0K2B15B6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "af7c5da3-4a2b-4a3e-8977-cff4f566f836"
      },
      "source": [
        "def sigmoid(z):\n",
        "    return 1/(1+np.exp(-z))\n",
        "\n",
        "z = np.linspace(-10,10,100)\n",
        "plt.plot(z, sigmoid(z))\n",
        "plt.xlabel('y')\n",
        "plt.ylabel('sig(y)')\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MznIeX3aa8JI",
        "colab_type": "text"
      },
      "source": [
        "## What is the gradient function?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3WZvGug3gY4",
        "colab_type": "text"
      },
      "source": [
        "The **gradient function** is very similar to but not the same as the derivative. The value of the gradient at a point is a tangent vector – a vector at each point; while the value of the derivative at a point is a cotangent vector – a function of vectors at each point. Essentially: the gradient is the direction and rate of greatest increase while the derivative is just a scalar value of the magintude of the rate of change at a point. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4apgOXmxa-Z8",
        "colab_type": "text"
      },
      "source": [
        "## What is gradient descent?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnBuYd3a5OJu",
        "colab_type": "text"
      },
      "source": [
        "**Gradient Descent** is the method to minimize the loss of your model in an effort to make it more accurate. If you were to imagine the loss function as an elevation map of a valley, the gradient descent method would find the point of lowest elevation corresponding to the lowest loss. It accomplishes this by looking at the gradient of the point where youre standing and using it as a guide to tell you where to go. The gradient shows you in which direction loss is decreasing the fastest. \n",
        "\n",
        "![descent](https://storage.ning.com/topology/rest/1.0/file/get/3713179836?profile=)(13)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_dYdwcP6SCa",
        "colab_type": "text"
      },
      "source": [
        "### Learning rate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwrW6hW56T6I",
        "colab_type": "text"
      },
      "source": [
        "**Learning rate** is a coefficient that modifies the gradient at each step. This can be used to either increase (LR greater than 1) or decrease (LT lower than 1) the size of the step made by the gradeint descent function. You must be careful as the learning rate can make or break your model. If the LR is too high than it will take too large of steps and will continually over shoot the global minimum of the loss function, rendering your model useless. However if it is too small then the model will not find the minimum efficiently. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uv9f2R0HaadR",
        "colab_type": "text"
      },
      "source": [
        "# Building a Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLNlIeeSbCKy",
        "colab_type": "text"
      },
      "source": [
        "## Model Structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2QWINKRIXqM",
        "colab_type": "text"
      },
      "source": [
        "Artifical Neural Networks are made up of various different layers in sequence that each have their own special jobs. The architecture of these models generally look something like this: \n",
        "\n",
        "![Model](https://miro.medium.com/max/1400/1*LTRcAyl6zuuJvpU-5KECZA.png)(11)\n",
        "\n",
        "This type of model is called **Sequential** which means that an input tensor, for example a vectorized image, is passed through a series of layers. The output of this model is typically a single value or a 1D vector, for example a classification of the contents of the image. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQGlGiQ2dTs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lets start our sequential model\n",
        "model = Sequential()\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "#reshape data to fit model\n",
        "X_train = X_train.reshape(60000,28,28,1)\n",
        "X_test = X_test.reshape(10000,28,28,1)\n",
        "#one-hot encode target column\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVTyewHsJx7I",
        "colab_type": "text"
      },
      "source": [
        "## Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI3fTm8lJzfa",
        "colab_type": "text"
      },
      "source": [
        "While there are many many kinds of **layers** to use in neural networks, this class covered three of the most important and most used: Dense, Pooling, and Convolutional. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSX0r2lLbIJb",
        "colab_type": "text"
      },
      "source": [
        "### Convolutional Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdQjnysQOWfa",
        "colab_type": "text"
      },
      "source": [
        "The presence of a convolutional layer is what sets Convolutional Neural Networks apart from their normal Artifical neural network counterparts. Convolution is, according to Wolfram Alpha, a \"blending of one function of another\" (6). More specifically, its an intergral that expressed the overlap of one function after its been flipped and shifted over another. In the context of a CNN, its essentially a method to filter a tensor.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeKhoOSlgE2M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "0f354377-f54e-46ed-876b-c39a6af9d16e"
      },
      "source": [
        "model.add(Conv2D(64, kernel_size=5, activation='relu', input_shape=(28,28,1)))\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 24, 24, 64)        1664      \n",
            "=================================================================\n",
            "Total params: 1,664\n",
            "Trainable params: 1,664\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdTPRraJOARk",
        "colab_type": "text"
      },
      "source": [
        "### Pooling Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mr_ZOa8DOACY",
        "colab_type": "text"
      },
      "source": [
        "These are usually used to decrease the size of the working data within a model without decreasing the integreity of the model. By taking a downsample of a layer thorugh pooling we can reduce the number of operations required for the following layer to prodice a valid result. One method of doing this is Max-Pooling, which essentially takes the max value of a sub-tensor within the layer output and returns it. When this is performed over the entire output tensor, you can saefly reduce its size significantly (6). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3bBFcqygjn7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "793d810a-67d8-4032-bd32-468ba3ddfeaa"
      },
      "source": [
        "model.add(MaxPool2D(strides=2, padding='valid'))\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 24, 24, 64)        1664      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
            "=================================================================\n",
            "Total params: 1,664\n",
            "Trainable params: 1,664\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMXU3CE4mL-I",
        "colab_type": "text"
      },
      "source": [
        "### Flatten"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ9D3sl5mOav",
        "colab_type": "text"
      },
      "source": [
        "These layers are a more specific case of reshape layers. Flatten layers condense the tensor into a 1D vector, \"Flattening\" it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLizy6u0mTeD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "e7463fdf-9eb5-4aee-a566-21223caf706a"
      },
      "source": [
        "model.add(Flatten())\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 24, 24, 64)        1664      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 9216)              0         \n",
            "=================================================================\n",
            "Total params: 1,664\n",
            "Trainable params: 1,664\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-wBTvahN9uY",
        "colab_type": "text"
      },
      "source": [
        "### Dense Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KkORdQwN_iW",
        "colab_type": "text"
      },
      "source": [
        "Also known as fully-connected layers. These can be thought of layers that perform a type of logistic regression on their input vectors (5). Dense layers can be stacked sequentially to model increasingly complex mathemiatical equations but they are not without limitation. Because they will always get the same output for the same input, they cannot detect patterns over time or the affects of repititon. Recurrent layers can resolve this, but they were not focused on in this class. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMK-CjDYlbQs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "7300e000-c3a5-42e5-ab37-08a9a44f8c0b"
      },
      "source": [
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 24, 24, 64)        1664      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                92170     \n",
            "=================================================================\n",
            "Total params: 93,834\n",
            "Trainable params: 93,834\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hqS8FMrPoO_",
        "colab_type": "text"
      },
      "source": [
        "### Other layers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBm5b0PfPqkt",
        "colab_type": "text"
      },
      "source": [
        "This list of layers is not exhaustive, its just to showcase what other kinds of layers are commonly used. \n",
        "\n",
        "- Normalization: These layers are simple, they normalize the values across the tensor(6). These are particualt useful for batch normalization and feature scaling. \n",
        "\n",
        "- Reshape: These layers reshape in the input tensor. These dont change the data in any way, they simply modulate the dimensions to fit the next layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEagRo1tacdc",
        "colab_type": "text"
      },
      "source": [
        "# Compilng a Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEXFnP-TnHBw",
        "colab_type": "text"
      },
      "source": [
        "## Loss Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5_DRefSnJfl",
        "colab_type": "text"
      },
      "source": [
        "The loss functions can be thought of a metric determining how wrong your model is. Your model iterates itself over and over again thorugh gradient descent trying to minimize the output of the loss function. Choosing your loss function well is critical as how you rmodel develops hinges on it being effective. The primary parameter one should consider while chossing a loss function is the problem type. For example, binary classification needs a loss function like binary-cross-entropy while a normal regression problem might best utilize mean-squared-error (15).\n",
        "\n",
        "![Loss](https://algorithmia.com/blog/wp-content/uploads/2018/04/word-image-4.png)(12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHR0gmZTbRTp",
        "colab_type": "text"
      },
      "source": [
        "## Optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-G_97RUsv0J",
        "colab_type": "text"
      },
      "source": [
        "Optimizers act as the tool to minimize the loss function, the staple optimizer is standard gradient descent but that is not the only one. In fact, it is one of the least efficient (15). One of the best optimizers is ADAM or Adpative Moment Estimation. Here is a comparison of a slew of a few optimizer's effectivness when faced with a saddle point (16).\n",
        "\n",
        "![Opti](https://miro.medium.com/max/1400/1*ZxvrAp_3VubvJf0K3NPT7Q.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okSNmVpwbVCD",
        "colab_type": "text"
      },
      "source": [
        "## Activation Functions "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCPPBrAuvCpk",
        "colab_type": "text"
      },
      "source": [
        "The activation function is the fucntion that the model output passes through. Its main use is to make the output something useful and definitive. A marquee example is the sigmoid function from earlier. Here is a compoarison of the most popular activation functions and what they loom like. \n",
        "\n",
        "![Activation](http://rasbt.github.io/mlxtend/user_guide/general_concepts/activation-functions_files/activation-functions.png)(17)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaYKGV_moWEd",
        "colab_type": "text"
      },
      "source": [
        "## Our Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pObBbsJwPBf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk1ilUhRahTo",
        "colab_type": "text"
      },
      "source": [
        "# Training a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXcdrcdzbdCh",
        "colab_type": "text"
      },
      "source": [
        "## Data splitting "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oZLBpH6xgg2",
        "colab_type": "text"
      },
      "source": [
        "In order to train your model, you need data. In order to train your model properly, you have to *split* your data. Typically, you need to split your data into 2 sets, but sometimes there can even be a third (18). \n",
        "- The **Train** set is the piece of your dataset used to fit your model. It is usually comprised of 70-80 percent of all your data.\n",
        "- The **Test** set is the piece of the the dataset that the already fitted model is evaulated against. It is *critical* that your model never trains on any of this data or the model is compromised and is at extreme risk of overfitting. It is usaully 10 - 20 percent of the data. \n",
        "- The **Validation** set is sort of an inbetween. Essentially this set is used to fine tune your model. So while the model never trains on this data, the model sees it frequently while you fine tune model parameters. It is usaully 10 - 20 percent of the data. This set is not always used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BLpoZz4baQ0",
        "colab_type": "text"
      },
      "source": [
        "## Overfitting and Underfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEAQY7iWy-Ez",
        "colab_type": "text"
      },
      "source": [
        "Overfitting is what happens when a model is tuned too closely to the particular data it was trained on rather than the larger population of data it could be given. This happens often when the data is not properly split. If you train your model on the entire set and dont specify a test set, overfitting is a high risk. \n",
        "\n",
        "Underfitting is similar and is a more obvious issue. Basically, the test set isnt comprehensive enough to properly train the model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBlvi_U7z7th",
        "colab_type": "text"
      },
      "source": [
        "## Our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlZihfRwz-8a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "08b64ac8-b049-478c-d5b2-cb840ca0fc37"
      },
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.6040 - accuracy: 0.9482 - val_loss: 0.1103 - val_accuracy: 0.9698\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0922 - accuracy: 0.9752 - val_loss: 0.1130 - val_accuracy: 0.9733\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0832 - accuracy: 0.9775 - val_loss: 0.1320 - val_accuracy: 0.9622\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa690241748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHIcdG1xakV3",
        "colab_type": "text"
      },
      "source": [
        "# Finetuning a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Plyq2HgEbgLi",
        "colab_type": "text"
      },
      "source": [
        "Fine tuning is when you take a pretrained model and add your own layers on top to train specifically for your own data set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVdk9cXo2pCY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "cf6a7af4-556a-467b-8819-0482fe3b8ab6"
      },
      "source": [
        "conv_base = MobileNet(\n",
        "    weights='imagenet', \n",
        "    include_top=False, \n",
        "    input_shape=(150, 150, 3))\n",
        "\n",
        "# Freeze convolutional base.\n",
        "conv_base.trainable = False\n",
        "\n",
        "# Add layers on top to fine-tune.\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "conv_base.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "  if layer.name == 'conv5_block2_2_conv': ## change frozen layer\n",
        "    set_trainable = True\n",
        "  if set_trainable:\n",
        "    layer.trainable = True\n",
        "  else:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=optimizers.RMSprop(lr=2e-5), \n",
        "    metrics=['acc'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  warnings.warn('`input_shape` is undefined or non-square, '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "mobilenet_1.00_224 (Model)   (None, 4, 4, 1024)        3228864   \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               4194560   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 7,423,681\n",
            "Trainable params: 4,194,817\n",
            "Non-trainable params: 3,228,864\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ifi23u0Nad5s",
        "colab_type": "text"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtSJ79NnaiwX",
        "colab_type": "text"
      },
      "source": [
        "1. https://github.com/schneider128k/machine_learning_course/blob/master/slides/1_a_slides.pdf\n",
        "2. https://www.bogotobogo.com/python/scikit-learn/scikit_machine_learning_Supervised_Learning_Unsupervised_Learning.php\n",
        "3. https://en.wikipedia.org/wiki/Iris_flower_data_set\n",
        "4. https://en.wikipedia.org/wiki/Gradient\n",
        "5. https://medium.com/datathings/dense-layers-explained-in-a-simple-way-62fe1db0ed75\n",
        "6. https://forums.fast.ai/t/dense-vs-convolutional-vs-fully-connected-layers/191\n",
        "7. https://www.google.com/imgres?imgurl=https%3A%2F%2Fdpzbhybb2pdcj.cloudfront.net%2Fcai%2FFigures%2F01fig01_alt.jpg&imgrefurl=https%3A%2F%2Flivebook.manning.com%2Fbook%2Fdeep-learning-with-javascript%2Fchapter-1&tbnid=KCcYlQBPAjszxM&vet=12ahUKEwj76PC6jILpAhVCFlMKHQBkDhQQMygaegQIARBA..i&docid=cXfpmu-XMVtHIM&w=590&h=386&q=symbolic%20ai%20flowchart&ved=2ahUKEwj76PC6jILpAhVCFlMKHQBkDhQQMygaegQIARBA\n",
        "8. https://www.breezetree.com/images/simple-flow-chart-example.png\n",
        "9. https://www.researchgate.net/figure/Reinforcement-Learning-Agent-and-Environment_fig2_323867253\n",
        "10. https://www.researchgate.net/figure/Deep-learning-diagram_fig5_323784695\n",
        "11. https://towardsdatascience.com/simple-introduction-to-convolutional-neural-networks-cdf8d3077bac\n",
        "12. https://algorithmia.com/blog/introduction-to-loss-functions\n",
        "13. https://storage.ning.com/topology/rest/1.0/file/get/3713179836?profile=RESIZE_710x\n",
        "14. https://keras.io/optimizers/\n",
        "15. https://keras.io/losses/\n",
        "16. https://miro.medium.com/max/1400/1*ZxvrAp_3VubvJf0K3NPT7Q.gif\n",
        "17. http://rasbt.github.io/mlxtend/user_guide/general_concepts/activation-functions_files/activation-functions.png\n",
        "18. https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7"
      ]
    }
  ]
}